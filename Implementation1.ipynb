{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":120126,"databundleVersionId":14369730,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers librosa soundfile accelerate pytorch-lightning language-tool-python xgboost textstat sentence-transformers\n!pip install openai-whisper --no-deps\n!pip install tiktoken ffmpeg-python\n!pip install Levenshtein\n!apt-get update\n!apt-get install -y openjdk-17-jdk-headless\n!java -version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:10:43.963776Z","iopub.execute_input":"2025-12-15T21:10:43.964118Z","iopub.status.idle":"2025-12-15T21:12:43.479618Z","shell.execute_reply.started":"2025-12-15T21:10:43.964095Z","shell.execute_reply":"2025-12-15T21:12:43.478810Z"},"_kg_hide-input":false,"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.5)\nCollecting language-tool-python\n  Downloading language_tool_python-3.1.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nCollecting textstat\n  Downloading textstat-0.7.12-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.2)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.10.0)\nRequirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.8.2)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.15.2)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from textstat) (3.9.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.23)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.5.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->textstat) (8.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading language_tool_python-3.1.0-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading textstat-0.7.12-py3-none-any.whl (176 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.6/176.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, textstat, nvidia-cusparse-cu12, nvidia-cudnn-cu12, language-tool-python, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed language-tool-python-3.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyphen-0.17.2 textstat-0.7.12\nCollecting openai-whisper\n  Downloading openai_whisper-20250625.tar.gz (803 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=4973f229c18dfa5b63810a82af1d8fe5abd6c113243a8a89b7d2066c3699eb7d\n  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\nSuccessfully built openai-whisper\nInstalling collected packages: openai-whisper\nSuccessfully installed openai-whisper-20250625\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nCollecting ffmpeg-python\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\nDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ffmpeg-python\nSuccessfully installed ffmpeg-python-0.2.0\nCollecting Levenshtein\n  Downloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nDownloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\nSuccessfully installed Levenshtein-0.27.3 rapidfuzz-3.14.3\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nHit:4 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:5 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease    \nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nHit:7 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\nGet:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,204 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]       \nGet:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:12 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]          \nGet:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \nGet:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,850 kB]\nGet:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,410 kB]\nGet:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,542 kB] \nGet:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,964 kB]\nFetched 38.2 MB in 4s (10.8 MB/s)                                              \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  openjdk-17-jre-headless\nSuggested packages:\n  openjdk-17-demo openjdk-17-source libnss-mdns fonts-dejavu-extra\n  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n  | fonts-wqy-zenhei fonts-indic\nThe following NEW packages will be installed:\n  openjdk-17-jdk-headless openjdk-17-jre-headless\n0 upgraded, 2 newly installed, 0 to remove and 189 not upgraded.\nNeed to get 120 MB of archives.\nAfter this operation, 272 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.17+10-1~22.04 [48.3 MB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.17+10-1~22.04 [71.4 MB]\nFetched 120 MB in 1s (83.8 MB/s)                   \nSelecting previously unselected package openjdk-17-jre-headless:amd64.\n(Reading database ... 128639 files and directories currently installed.)\nPreparing to unpack .../openjdk-17-jre-headless_17.0.17+10-1~22.04_amd64.deb ...\nUnpacking openjdk-17-jre-headless:amd64 (17.0.17+10-1~22.04) ...\nSelecting previously unselected package openjdk-17-jdk-headless:amd64.\nPreparing to unpack .../openjdk-17-jdk-headless_17.0.17+10-1~22.04_amd64.deb ...\nUnpacking openjdk-17-jdk-headless:amd64 (17.0.17+10-1~22.04) ...\nSetting up openjdk-17-jre-headless:amd64 (17.0.17+10-1~22.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\nSetting up openjdk-17-jdk-headless:amd64 (17.0.17+10-1~22.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\nopenjdk version \"17.0.17\" 2025-10-21\nOpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\nOpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport whisper\nimport librosa\nimport Levenshtein\nimport language_tool_python\nimport textstat\nimport xgboost as xgb\nfrom tqdm.notebook import tqdm\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:12:43.481277Z","iopub.execute_input":"2025-12-15T21:12:43.481558Z","iopub.status.idle":"2025-12-15T21:13:35.124869Z","shell.execute_reply.started":"2025-12-15T21:12:43.481533Z","shell.execute_reply":"2025-12-15T21:13:35.124028Z"}},"outputs":[{"name":"stderr","text":"2025-12-15 21:13:04.385539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765833184.794905      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765833184.893145      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Paths\nBASE_PATH = \"/kaggle/input/shl-intern-hiring-assessment-2025/dataset\"\nTRAIN_AUDIO_DIR = f\"{BASE_PATH}/audios/train\"\nTEST_AUDIO_DIR = f\"{BASE_PATH}/audios/test\"\n\n# Load Whisper\nmodel = whisper.load_model(\"medium.en\")\n\ndef transcribe_data(df, audio_dir):\n    transcriptions = []\n    print(f\"Transcribing {len(df)} files...\")\n    for idx, row in tqdm(df.iterrows(), total=len(df)):\n        filename = row['filename']\n        if not filename.endswith('.wav'): filename += '.wav'\n        path = os.path.join(audio_dir, filename)\n        \n        try:\n            # Beam size 1 helps prevent over-correction of grammar\n            result = model.transcribe(path, beam_size=1, language=\"en\")\n            transcriptions.append(result['text'].strip())\n        except:\n            transcriptions.append(\"\")\n    return transcriptions\n\n# Load Data\ntrain_df = pd.read_csv(f\"{BASE_PATH}/csvs/train.csv\")\ntest_df = pd.read_csv(f\"{BASE_PATH}/csvs/test.csv\")\n\n# Run Transcription (checks if file exists to save time)\nif os.path.exists(\"train_transcribed.csv\"):\n    train_df = pd.read_csv(\"train_transcribed.csv\")\n    test_df = pd.read_csv(\"test_transcribed.csv\")\n    print(\"Loaded saved transcriptions.\")\nelse:\n    train_df['transcription'] = transcribe_data(train_df, TRAIN_AUDIO_DIR)\n    test_df['transcription'] = transcribe_data(test_df, TEST_AUDIO_DIR)\n    train_df.to_csv(\"train_transcribed.csv\", index=False)\n    test_df.to_csv(\"test_transcribed.csv\", index=False)\n\n# Fill NaNs\ntrain_df['transcription'] = train_df['transcription'].fillna(\"\")\ntest_df['transcription'] = test_df['transcription'].fillna(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:13:35.125716Z","iopub.execute_input":"2025-12-15T21:13:35.126578Z","iopub.status.idle":"2025-12-15T22:01:20.603413Z","shell.execute_reply.started":"2025-12-15T21:13:35.126557Z","shell.execute_reply":"2025-12-15T22:01:20.602852Z"}},"outputs":[{"name":"stderr","text":"100%|██████████████████████████████████████| 1.42G/1.42G [00:08<00:00, 178MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"Transcribing 409 files...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/409 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5593e0f8408c4327b4f45d53b75f7552"}},"metadata":{}},{"name":"stdout","text":"Transcribing 197 files...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6275ba8b38824098b1add4185383c800"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# --- 1. Re-Transcribe with Wav2Vec2 ---\nfrom transformers import pipeline\nimport librosa\nimport os\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Load Wav2Vec2 (Acoustic model, preserves errors)\nasr_dumb = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\", device=0 if torch.cuda.is_available() else -1)\n\ndef transcribe_wav2vec(df, audio_dir):\n    texts = []\n    print(f\"Re-transcribing {len(df)} files in {audio_dir}...\")\n    \n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        fname = row['filename']\n        if not fname.endswith('.wav'): fname += '.wav'\n        path = os.path.join(audio_dir, fname)\n        \n        try:\n            # Wav2Vec2 requires 16kHz audio\n            audio, _ = librosa.load(path, sr=16000)\n            # Transcribe\n            result = asr_dumb(audio, chunk_length_s=30)['text'].lower()\n            texts.append(result)\n        except Exception as e:\n            print(f\"Error {fname}: {e}\")\n            texts.append(\"\")\n            \n    return texts\n\n# 1. Run Transcription\ntrain_df['transcription_raw'] = transcribe_wav2vec(train_df, TRAIN_AUDIO_DIR)\ntest_df['transcription_raw'] = transcribe_wav2vec(test_df, TEST_AUDIO_DIR)\n\n# 2. Swap columns (So your existing code works)\ntrain_df['transcription'] = train_df['transcription_raw']\ntest_df['transcription'] = test_df['transcription_raw']\n\n# 3. Save immediately\ntrain_df.to_csv(\"train_wav2vec.csv\", index=False)\ntest_df.to_csv(\"test_wav2vec.csv\", index=False)\nprint(\"Saved new raw transcriptions!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T22:56:12.524899Z","iopub.execute_input":"2025-12-15T22:56:12.525473Z","iopub.status.idle":"2025-12-15T22:59:24.627259Z","shell.execute_reply.started":"2025-12-15T22:56:12.525433Z","shell.execute_reply":"2025-12-15T22:59:24.626613Z"}},"outputs":[{"name":"stderr","text":"Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Re-transcribing 409 files in /kaggle/input/shl-intern-hiring-assessment-2025/dataset/audios/train...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/409 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9064a9a45bdd464ba3bf66983e6d7022"}},"metadata":{}},{"name":"stdout","text":"Re-transcribing 197 files in /kaggle/input/shl-intern-hiring-assessment-2025/dataset/audios/test...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b123925c86945f1bcd2b28bb5022ec2"}},"metadata":{}},{"name":"stdout","text":"Saved new raw transcriptions!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# --- 3. Advanced Feature Engineering ---\n\n# Initialize Tools\ntool = language_tool_python.LanguageTool('en-US')\ngec_pipe = pipeline(\"text2text-generation\", model=\"vennify/t5-base-grammar-correction\", device=0 if torch.cuda.is_available() else -1)\nembedder = SentenceTransformer('all-MiniLM-L6-v2')\n\ntqdm.pandas() \n\ndef extract_features(row, audio_dir):\n    filename = row['filename']\n    text = row['transcription']\n    features = {}\n\n    # --- 1. PROSODY (Audio) ---\n    path = os.path.join(audio_dir, filename if filename.endswith('.wav') else f\"{filename}.wav\")\n    try:\n        y, sr = librosa.load(path, sr=None)\n        duration = librosa.get_duration(y=y, sr=sr)\n        \n        # Detect non-silent chunks to calculate true speaking time\n        non_silent = librosa.effects.split(y, top_db=20)\n        non_silent_time = sum([end - start for start, end in non_silent]) / sr\n        \n        word_count = len(str(text).split())\n        \n        features['speech_rate'] = word_count / duration if duration > 0 else 0\n        features['articulation_rate'] = word_count / non_silent_time if non_silent_time > 0 else 0\n        features['silence_ratio'] = (duration - non_silent_time) / duration if duration > 0 else 0\n        features['duration'] = duration\n    except:\n        features['speech_rate'] = 0\n        features['articulation_rate'] = 0\n        features['silence_ratio'] = 0\n        features['duration'] = 0\n\n    # --- 2. NEURAL GRAMMAR (GEC Distance) ---\n    try:\n        if len(str(text)) > 1:\n            # Ask T5 to fix the grammar\n            fixed_text = gec_pipe(f\"grammar: {text}\")[0]['generated_text']\n            # Normalized distance: How much did T5 change the original text?\n            features['grammar_distance'] = Levenshtein.distance(text, fixed_text) / len(text)\n        else:\n            features['grammar_distance'] = 0\n    except:\n        features['grammar_distance'] = 0\n\n    # --- 3. RULE-BASED GRAMMAR ---\n    try:\n        matches = tool.check(text)\n        features['error_count'] = len(matches)\n        features['error_density'] = len(matches) / len(text.split()) if len(text.split()) > 0 else 0\n        features['complexity'] = textstat.flesch_kincaid_grade(text)\n    except:\n        features['error_count'] = 0\n        features['error_density'] = 0\n        features['complexity'] = 0\n\n    return pd.Series(features)\n\nprint(\"Extracting Advanced Features (Train)...\")\ntrain_feats = train_df.progress_apply(lambda row: extract_features(row, TRAIN_AUDIO_DIR), axis=1)\n\nprint(\"Extracting Advanced Features (Test)...\")\ntest_feats = test_df.progress_apply(lambda row: extract_features(row, TEST_AUDIO_DIR), axis=1)\n\n# --- 4. EMBEDDINGS (Semantic) ---\nprint(\"Generating Embeddings...\")\nX_train_emb = embedder.encode(train_df['transcription'].fillna(\"\").tolist(), show_progress_bar=True)\nX_test_emb = embedder.encode(test_df['transcription'].fillna(\"\").tolist(), show_progress_bar=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T22:59:36.546371Z","iopub.execute_input":"2025-12-15T22:59:36.547174Z","iopub.status.idle":"2025-12-15T23:23:37.323792Z","shell.execute_reply.started":"2025-12-15T22:59:36.547145Z","shell.execute_reply":"2025-12-15T23:23:37.323142Z"}},"outputs":[{"name":"stderr","text":"WARNING:language_tool_python.server:Unclosed server (server still running at http://127.0.0.1:8317/v2/). Closing it now.\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Extracting Advanced Features (Train)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/409 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cadfb1adf829471cb18f3ee4bb696b6f"}},"metadata":{}},{"name":"stdout","text":"Extracting Advanced Features (Test)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8efd5fa4042140fcbb36b2dabedba1b3"}},"metadata":{}},{"name":"stdout","text":"Generating Embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d917adc2054cc89c022a91c7212ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27c6c9110aca4598a75a9ad3e2433c5a"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Define function to calculate Vocabulary Richness\ndef get_unique_ratio(text):\n    words = str(text).lower().split()\n    if len(words) == 0:\n        return 0\n    return len(set(words)) / len(words)\n\n# Apply to existing dataframes\nprint(\"Adding missing 'unique_ratio' column...\")\ntrain_feats['unique_ratio'] = train_df['transcription'].apply(get_unique_ratio)\ntest_feats['unique_ratio'] = test_df['transcription'].apply(get_unique_ratio)\n\nprint(\"Done! Columns are now:\", train_feats.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T23:23:37.325442Z","iopub.execute_input":"2025-12-15T23:23:37.325766Z","iopub.status.idle":"2025-12-15T23:23:37.340977Z","shell.execute_reply.started":"2025-12-15T23:23:37.325748Z","shell.execute_reply":"2025-12-15T23:23:37.340278Z"}},"outputs":[{"name":"stdout","text":"Adding missing 'unique_ratio' column...\nDone! Columns are now: ['speech_rate', 'articulation_rate', 'silence_ratio', 'duration', 'grammar_distance', 'error_count', 'error_density', 'complexity', 'unique_ratio']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Concatenate explicit features + raw embeddings\nX_train_full = pd.concat([train_feats, pd.DataFrame(X_train_emb)], axis=1)\nX_test_full = pd.concat([test_feats, pd.DataFrame(X_test_emb)], axis=1)\n\n# Ensure string column names for XGBoost\nX_train_full.columns = X_train_full.columns.astype(str)\nX_test_full.columns = X_test_full.columns.astype(str)\n\ny_train = train_df['label']\n\n#  FEATURE SELECTION (Recursive Feature Elimination approach)\n# We train a quick model to see what actually matters\nprint(\"Running Feature Selection...\")\nselector_model = xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\nselector_model.fit(X_train_full, y_train)\n\n# Get feature importances\nimportances = selector_model.feature_importances_\nindices = np.argsort(importances)[::-1] # Sort descending\n\n# Keep top 100 features (Embeddings + specific grammar features)\ntop_n = 100 \ntop_indices = indices[:top_n]\nselected_cols = X_train_full.columns[top_indices]\n\nprint(f\"Selected Top {top_n} features.\")\n\n# Filter datasets\nX_train_selected = X_train_full[selected_cols]\nX_test_selected = X_test_full[selected_cols]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T23:23:37.341611Z","iopub.execute_input":"2025-12-15T23:23:37.341786Z","iopub.status.idle":"2025-12-15T23:23:40.063156Z","shell.execute_reply.started":"2025-12-15T23:23:37.341772Z","shell.execute_reply":"2025-12-15T23:23:40.062321Z"}},"outputs":[{"name":"stdout","text":"Running Feature Selection...\nSelected Top 100 features.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from scipy.stats import pearsonr\n\n# 3. ROBUST TRAINING (5-Fold CV)\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros(len(X_train_selected))\ntest_preds = np.zeros(len(X_test_selected))\nrmse_scores = []\npearson_scores = []  # Track Pearson scores\n\nprint(\"\\nTraining Final Model...\")\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_selected, y_train)):\n    X_tr, X_val = X_train_selected.iloc[train_idx], X_train_selected.iloc[val_idx]\n    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    # Balanced Parameters: Less aggressive regularization than before\n    model = xgb.XGBRegressor(\n        n_estimators=2000,\n        learning_rate=0.02,    # Slightly higher to allow learning\n        max_depth=4,           # Depth 4 captures more interaction than 3\n        subsample=0.8,\n        colsample_bytree=0.8,  # Allow access to more features\n        n_jobs=-1,\n        random_state=42\n    )\n    \n    model.fit(\n        X_tr, y_tr,\n        eval_set=[(X_val, y_val)],\n        early_stopping_rounds=100,\n        verbose=False\n    )\n    \n    # Clip predictions to valid range 0-5\n    val_pred = np.clip(model.predict(X_val), 0, 5)\n    oof_preds[val_idx] = val_pred\n    test_preds += model.predict(X_test_selected) / 5\n    \n    # Calculate metrics\n    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n    pearson = pearsonr(y_val, val_pred)[0]\n    \n    rmse_scores.append(rmse)\n    pearson_scores.append(pearson)\n    \n    print(f\"Fold {fold+1} | RMSE: {rmse:.4f} | Pearson: {pearson:.4f}\")\n\nprint(f\"\\nAverage CV RMSE: {np.mean(rmse_scores):.4f}\")\nprint(f\"Average CV Pearson: {np.mean(pearson_scores):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T23:27:34.852907Z","iopub.execute_input":"2025-12-15T23:27:34.853229Z","iopub.status.idle":"2025-12-15T23:27:44.002563Z","shell.execute_reply.started":"2025-12-15T23:27:34.853208Z","shell.execute_reply":"2025-12-15T23:27:44.001846Z"}},"outputs":[{"name":"stdout","text":"\nTraining Final Model...\nFold 1 | RMSE: 0.6691 | Pearson: 0.5464\nFold 2 | RMSE: 0.5555 | Pearson: 0.6192\nFold 3 | RMSE: 0.6620 | Pearson: 0.6833\nFold 4 | RMSE: 0.5364 | Pearson: 0.6554\nFold 5 | RMSE: 0.5860 | Pearson: 0.6607\n\nAverage CV RMSE: 0.6018\nAverage CV Pearson: 0.6330\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"final_test_preds = np.clip(test_preds, 0, 5)\n\nsubmission = pd.DataFrame({\n    'filename': test_df['filename'],\n    'label': final_test_preds\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T23:27:47.281145Z","iopub.execute_input":"2025-12-15T23:27:47.281924Z","iopub.status.idle":"2025-12-15T23:27:47.290112Z","shell.execute_reply.started":"2025-12-15T23:27:47.281899Z","shell.execute_reply":"2025-12-15T23:27:47.289487Z"}},"outputs":[{"name":"stdout","text":"Saved submission.csv\n    filename     label\n0  audio_141  2.819240\n1  audio_114  3.113828\n2   audio_17  2.865006\n3   audio_76  4.273753\n4  audio_156  2.971206\n","output_type":"stream"}],"execution_count":25}]}